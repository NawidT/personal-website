{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! source personalvenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model_name='text-davinci-003', \n",
    "    temperature=0, \n",
    "    max_tokens=100, \n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "text = \"Fast, good on the ball. Plays for Arsenal\"\n",
    "player_template = \"\"\"\n",
    "Pretend to be an energetic sports analyst. Return me a soccer player who is {text}.\n",
    "\"\"\"\n",
    "prompt_temp = PromptTemplate(input_variables=[\"text\"], template=player_template)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mats Hummels is a German professional soccer player who plays as a defender for Borussia Dortmund and the German national team. He is a Muslim and is known for his strong defensive skills and leadership on the field. He has won numerous awards, including the German Footballer of the Year in 2016.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"German and Muslim defender\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from langchain.document_loaders import GoogleDriveLoader\n",
    "loader = GoogleDriveLoader(document_ids=['1m7ItHpUdr41yNzr6I3VMI1XvbrnKRPNX5Vs-najdzb4'])\n",
    "data = loader.load() \"\"\"\n",
    "\n",
    "from llama_index import download_loader\n",
    "GoogleDocsReader = download_loader('GoogleDocsReader')\n",
    "\n",
    "gdoc_ids = ['1m7ItHpUdr41yNzr6I3VMI1XvbrnKRPNX5Vs-najdzb4']\n",
    "loader = GoogleDocsReader()\n",
    "documents = loader.load_data(document_ids=gdoc_ids)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ntahmid/Documents/Coding/Work/personal-website/virtualenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf (from -r /Users/ntahmid/Documents/Coding/Work/personal-website/virtualenv/lib/python3.11/site-packages/llama_index/readers/llamahub_modules/file/pdf/requirements.txt (line 1))\n",
      "  Using cached pypdf-3.10.0-py3-none-any.whl (255 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-3.10.0\n",
      "3\n",
      "Collecting PyMuPDF (from -r /Users/ntahmid/Documents/Coding/Work/personal-website/virtualenv/lib/python3.11/site-packages/llama_index/readers/llamahub_modules/file/pymu_pdf/requirements.txt (line 1))\n",
      "  Downloading PyMuPDF-1.22.3-cp311-cp311-macosx_11_0_arm64.whl (12.7 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.7/12.7 MB 2.8 MB/s eta 0:00:005\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.22.3\n",
      "b'ABOUT\\nName: Akhter (Nawid) Tahmid, Number: +1 4042594142, Email: atahmid3@gatech.edu,\\nInstagram: @nawid.tahmid, LinkedIn: https://www.linkedin.com/in/akhter-tahmid/, GitHub:\\nhttps://github.com/nawidt\\nEDUCATION\\nGeorgia Institute of Technology, August 2021 \\xe2\\x80\\x93 December 2024\\nB.S. in Computer Science, Atlanta, GA\\nGPA: 3.20/4.00 Major GPA: 3.53/4.00\\nConcentrations (Threads): Intelligence, Information Networks\\nRelevant Coursework: Algorithms Honors, Data Structures, Artificial Intelligence, Objects &\\nDesign, Systems & Networks, Applied Combinatorics, Databases, Statistics, Computer\\nOrganization, Linear Algebra, Discrete Mathematics\\nEXPERIENCE\\nDatasoft\\nML Intern\\nMay 2023 \\xe2\\x80\\x93 Present\\nDhaka, Bangladesh\\nPerformed data analysis, trained, and evaluated neural network models using PyTorch, Pandas,\\nSQL, and Scikit-learn to integrate predictive capabilities into an IoT device to be used in fish\\nfarms, positively impacting the livelihoods of 1000\\xe2\\x80\\x99s of farmers in Bangladesh.\\nUtilized regularization and gradient boosting to accurately forecast dissolved oxygen and\\nammonia levels in fish farms to notify farmers to alter feeding rates, saving them 30% feed\\nrelated costs\\nARQ Dreambox AI\\nSoftware Engineering Intern\\nMay 2023 \\xe2\\x80\\x93 Present\\n(Remote) Atlanta, GA\\nBuilt the front-end of an innovative AI art-generated jewelry production company, utilizing React,\\nFramer Motion, Hugging Face, and Flask to create an engaging and visually captivating user\\ninterface for showcasing personalized and stunning jewelry pieces.\\nBig Data Club\\nProject Lead\\nAugust 2022 \\xe2\\x80\\x93 May 2023\\nAtlanta, GA\\nLed a team of 9 students to develop a web-app where users plot a hurricane and discover its\\neconomic impact\\nHeld SCRUM meetups to plan further sprints, and conducted ReactJS and Pandas learning\\nsessions to improve members\\xe2\\x80\\x99 proficiency\\n'\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from llama_index import download_loader\n",
    "\n",
    "PDFReader = download_loader(\"PDFReader\")\n",
    "loader = PDFReader()\n",
    "documents_norm = loader.load_data(file=Path('../../../../Downloads/FormattedResume.pdf'))\n",
    "print(len(documents_norm))\n",
    "\n",
    "PyMuPDFReader = download_loader(\"PyMuPDFReader\")\n",
    "loader = PyMuPDFReader()\n",
    "documents_fast = loader.load(file_path=Path('../../../../Downloads/FormattedResume.pdf'), metadata=False)\n",
    "print(documents_fast[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[Document(page_content='ABOUT\\nName: Akhter (Nawid) Tahmid, Number: +1 4042594142, Email: atahmid3@gatech.edu,\\nInstagram: @nawid.tahmid, LinkedIn: https://www.linkedin.com/in/akhter-tahmid/, GitHub:\\nhttps://github.com/nawidt\\nEDUCATION\\nGeorgia Institute of Technology, August 2021 – December 2024\\nB.S. in Computer Science, Atlanta, GA\\nGPA: 3.20/4.00 Major GPA: 3.53/4.00', metadata={}), Document(page_content='Concentrations (Threads): Intelligence, Information Networks\\nRelevant Coursework: Algorithms Honors, Data Structures, Artificial Intelligence, Objects &\\nDesign, Systems & Networks, Applied Combinatorics, Databases, Statistics, Computer\\nOrganization, Linear Algebra, Discrete Mathematics\\nEXPERIENCE\\nDatasoft\\nML Intern\\nMay 2023 – Present\\nDhaka, Bangladesh', metadata={}), Document(page_content='Performed data analysis, trained, and evaluated neural network models using PyTorch, Pandas,\\nSQL, and Scikit-learn to integrate predictive capabilities into an IoT device to be used in fish\\nfarms, positively impacting the livelihoods of 1000’s of farmers in Bangladesh.\\nUtilized regularization and gradient boosting to accurately forecast dissolved oxygen and', metadata={}), Document(page_content='ammonia levels in fish farms to notify farmers to alter feeding rates, saving them 30% feed\\nrelated costs\\nARQ Dreambox AI\\nSoftware Engineering Intern\\nMay 2023 – Present\\n(Remote) Atlanta, GA\\nBuilt the front-end of an innovative AI art-generated jewelry production company, utilizing React,\\nFramer Motion, Hugging Face, and Flask to create an engaging and visually captivating user', metadata={}), Document(page_content='interface for showcasing personalized and stunning jewelry pieces.\\nBig Data Club\\nProject Lead\\nAugust 2022 – May 2023\\nAtlanta, GA\\nLed a team of 9 students to develop a web-app where users plot a hurricane and discover its\\neconomic impact\\nHeld SCRUM meetups to plan further sprints, and conducted ReactJS and Pandas learning\\nsessions to improve members’ proficiency', metadata={}), Document(page_content='Implemented deep learning neural networks on PyTorch to predict road traffic and its economic\\ndamage caused by natural disasters\\nUtilized Pandas to collect and combine datasets from Kaggle used train AI model displayed on\\nReactJS with D3.js to visualize data\\nIntentional Design Studios\\nSoftware Engineering Intern\\nMay 2022 – August 2022\\nAtlanta, GA', metadata={}), Document(page_content='Optimized Firestore database retrieval times by 35% to SvelteJS frontend by scripting accurate\\ndata requirements in TypeScript\\nEnhanced latency on loading and landing pages by engineering local JavaScript and CSS\\ninterval-based animations\\nIntelligent Platforms for Crowdsourcing VIP\\nUndergraduate Researcher\\nJanuary 2021 – May 2023\\nAtlanta, GA', metadata={}), Document(page_content='Implemented Naive Bayes classification to identify and encourage valuable comments on our\\ndebate hosting app\\nManufactured a TF:IDF hashtag generator using NLP SpaCy with Python by expunging\\nstop-words and scoring terms\\nGenerated a Flask REST API backend to connect hashtag model and valuable comment\\nclassifier to React.js front end using Python\\nPROJECTS', metadata={}), Document(page_content='DayMaker, ReactJS, Express.js, Node.js, MongoDB, NLP, Google Cloud\\nFull-stack web application that automatically creates Google Calendar events from uploaded\\ndocuments, using a custom-trained Named Entity Recognition model to extract dates and\\nrelevant titles. The project was awarded Winner of Best Use of Google Cloud among 400 teams', metadata={}), Document(page_content='at HackTX 2021, and our team is currently working on building DayMaker without Google’s\\nservices\\nPeacekeepers, Unreal Engine, C++, Blender\\nLed a team of 5 to create a multiplayer first-person-shooter game. Designed weekly reports and\\nGAANT charts to manage development progress. Implemented realistic 3-dimensional projectile', metadata={}), Document(page_content='motion based bullet physics. Optimized frame rate by 175% by introducing foliage culling, baked\\nlighting and level-of-design techniques to smoothen the gaming experience. Created a python\\nscript to automate the standardization of geometry in the game object pipeline to improve teams\\nproductivity.\\nTECHNICAL SKILLS\\nLanguages: Python, Java, JavaScript, TypeScript, C++, Solidity, HTML/CSS', metadata={}), Document(page_content='Frameworks: ReactJS, React Native, Node.js, Svelte.js, Express.js, Next.js, Flask, Tailwind,\\nChakra UI, SpaCy, Django, Langchain, Pinecone, HuggingFace Hub, Framer', metadata={}), Document(page_content='Technologies: SQL, MongoDB, Postman, Firebase, Firestore, Docker, MATLAB, LaTeX, NumPy,\\nScikit-learn, Matplotlib, Pandas, Git, Unreal Engine, Blender\\nINTERESTS\\nI love soccer. I’m a huge Arsenal fan and have been supporting the team since 2011, when\\nArsene Wenger was Arsenal’s manager. I play soccer very often. I love traveling. Atlanta, GA', metadata={}), Document(page_content='has some nice parks that are within cycling distance. My favorite parks are probably Piedmont\\nPark and Historic Fourth Ward Splash Park. I love going to MLS games. I’ve been to 3 Atlanta\\nUnited matches at the Benz stadium. I love keeping up with the newest tech news, especially in\\nthe LLM space. In the technical space, I’m more into AI and ML, and I’m strong in frontend and', metadata={}), Document(page_content='backend development. I’m an organized person who prefers things neat and tidy, even if it\\nrequires extra effort\\nSTRENGTHS AND WEAKNESSES\\nStrengths: Neat and tidy, organized, love planning and scheduling tasks. I’m a fast learner.\\nOrganization leads to faster speed in the long term. Consistent performer who stays in the top\\nechelon for longer periods of time.', metadata={}), Document(page_content='Weakness: I focus heavily on organizing which leads to a lot of time spent on planning and\\nscheduling', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llama_index.readers import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=0)\n",
    "\n",
    "# convert llama_index Document to langchain Document\n",
    "texts = []\n",
    "for doc in documents_fast:\n",
    "    wrapper = Document(text=doc.text)\n",
    "    formatted = wrapper.to_langchain_format()\n",
    "    this_text = text_splitter.split_documents([formatted])\n",
    "    for text in this_text:\n",
    "        texts.append(text)\n",
    "\n",
    "# split documents to nodes/chunks\n",
    "print(len(texts))\n",
    "print(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "pinecone.init(api_key=os.getenv('PINECONE_API_KEY'), environment=os.getenv('PINECONE_ENVIRONMENT'))\n",
    "index = os.getenv('PINECONE_INDEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], index_name=index, embedding=embeddings)\n",
    "#docsem = Pinecone.from_existing_index(index_name=index, embedding=embeddings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine docs + query in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "prompt_template = \"Pretend you are Akhter (Nawid) Tahmid. Speak in a professional manner, but don't use complicated words. Don't use information outside of whats given. Answer the following question: {question}?\"\n",
    "llm = OpenAI(temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template),\n",
    "    verbose=False,\n",
    "    \n",
    ")\n",
    "\n",
    "qa_chain = load_qa_chain(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In 5-10 years, I see myself continuing to work in the tech industry, leveraging my skills in AI and ML, frontend and backend development, and software engineering. I hope to be in a position where I can continue to learn and grow, while also making an impact on the world.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Where do you see yourself in 5-10 years?\"\n",
    "docs = docsem.similarity_search(query) \n",
    "qa_chain.run(input_documents=docs, question=prompt_template.format(question=query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
